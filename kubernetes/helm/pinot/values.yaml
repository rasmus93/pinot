#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Default values for Pinot.

image:
  repository: apachepinot/pinot
  tag: release-0.10.0 # 0.10.0-SNAPSHOT-65dcfe785e-20220208-jdk11 # 0.10.0-SNAPSHOT-34f371d1cb-20220131-jdk11 -working # 0.10.0-SNAPSHOT-3c98a44696-20220201-jdk11 - lookup fix # latest-jdk11 # release-0.7.1
  pullPolicy: IfNotPresent

cluster:
  name: pinot-poc-cluster-new

imagePullSecrets: []

terminationGracePeriodSeconds: 30

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

probes:
  initialDelaySeconds: 60
  periodSeconds: 10

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# ------------------------------------------------------------------------------
# Pinot Controller:
# ------------------------------------------------------------------------------
controller:
  name: controller
  replicaCount: 1
  podManagementPolicy: Parallel
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}

  probes:
    endpoint: "/health"
    livenessEnabled: false
    readinessEnabled: false

  persistence:
    enabled: true
    accessMode: ReadWriteOnce
    size: 15G
    mountPath: /var/pinot/controller/data
    storageClass: ""

  data:
    dir: s3://wix-bi-pinot-warehouse/pinot-poc/controller-data

  vip:
    enabled: false
    host: pinot-controller
    port: 9000

  jvmOpts: "-Xmx4G -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xlog:gc*:file=/opt/pinot/gc-pinot-controller.log -javaagent:/opt/pinot/etc/jmx_prometheus_javaagent/jmx_prometheus_javaagent-0.12.0.jar=8008:/opt/pinot/etc/jmx_prometheus_javaagent/configs/pinot.yml"

  log4j2ConfFile: /opt/pinot/conf/log4j2.xml
  pluginsDir: /opt/pinot/plugins

  service:
    annotations:
      "prometheus.io/scrape": "true"
      "prometheus.io/port": "8008"
    clusterIP: "None"
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    type: ClusterIP
    port: 9000
    nodePort: ""
    protocol: TCP
    name: controller

  external:
    enabled: true
    type: LoadBalancer
    port: 9000
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-internal: "true"

  resources:
    requests:
      cpu: 3000m
      memory: 16Gi
    limits:
      cpu: 3000m
      memory: 16Gi

  nodeSelector: {}

  tolerations: []

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pinot-controller-node
                operator: In
                values:
                  - "true"

  podAnnotations:
    "prometheus.io/scrape": "true"
    "prometheus.io/port": "8008"

  updateStrategy:
    type: RollingUpdate

  # Use envFrom to define all of the ConfigMap or Secret data as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables
  envFrom: []
  #  - configMapRef:
  #      name: special-config
  #  - secretRef:
  #      name: test-secret

  # Use extraEnv to add individual key value pairs as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
  extraEnv: []
  #  - name: PINOT_CUSTOM_ENV
  #    value: custom-value

  # Extra configs will be appended to pinot-controller.conf file
  extra:
    configs: |-
      pinot.set.instance.id.to.hostname=true
      controller.task.scheduler.enabled=true
      controller.task.frequencyPeriod=1h
      controller.enable.storage.quota.check=false
      controller.local.temp.dir=/tmp/pinot-tmp-data/
      pinot.controller.storage.factory.class.s3=org.apache.pinot.plugin.filesystem.S3PinotFS
      pinot.controller.storage.factory.s3.region=us-east-1
      pinot.controller.segment.fetcher.protocols=file,http,s3
      pinot.controller.segment.fetcher.s3.class=org.apache.pinot.common.utils.fetcher.PinotFSSegmentFetcher
      controller.vip.enabled=true
      controller.vip.host=internal-a4cb7feaefcfb40bd89f422b22382bfc-1435608294.us-east-1.elb.amazonaws.com

# ------------------------------------------------------------------------------
# Pinot Broker:
# ------------------------------------------------------------------------------
broker:
  name: broker
  replicaCount: 2
  podManagementPolicy: Parallel
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}

  jvmOpts: "-Xms16G -Xmx16G -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xlog:gc*:file=/opt/pinot/gc-pinot-broker.log -javaagent:/opt/pinot/etc/jmx_prometheus_javaagent/jmx_prometheus_javaagent-0.12.0.jar=8008:/opt/pinot/etc/jmx_prometheus_javaagent/configs/pinot.yml"

  log4j2ConfFile: /opt/pinot/conf/log4j2.xml
  pluginsDir: /opt/pinot/plugins

  routingTable:
    builderClass: random

  probes:
    endpoint: "/health"
    livenessEnabled: true
    readinessEnabled: true

  service:
    annotations:
      "prometheus.io/scrape": "true"
      "prometheus.io/port": "8008"
    clusterIP: "None"
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    type: ClusterIP
    protocol: TCP
    port: 8099
    name: broker
    nodePort: ""

  external:
    enabled: true
    type: LoadBalancer
    port: 8099
    # For example, in private GKE cluster, you might add cloud.google.com/load-balancer-type: Internal
    annotations: 
      service.beta.kubernetes.io/aws-load-balancer-internal: "true"

  resources:
    requests:
      cpu: 4000m
      memory: 32Gi
    limits:
      cpu: 4000m
      memory: 32Gi

  nodeSelector: {}

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pinot-broker-node
                operator: In
                values:
                  - "true"

  tolerations: []

  podAnnotations:
    "prometheus.io/scrape": "true"
    "prometheus.io/port": "8008"

  updateStrategy:
    type: RollingUpdate

  # Use envFrom to define all of the ConfigMap or Secret data as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables
  envFrom: []
  #  - configMapRef:
  #      name: special-config
  #  - secretRef:
  #      name: test-secret

  # Use extraEnv to add individual key value pairs as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
  extraEnv: []
  #  - name: PINOT_CUSTOM_ENV
  #    value: custom-value

  # Extra configs will be appended to pinot-broker.conf file
  extra:
    configs: |-
      pinot.set.instance.id.to.hostname=true

# ------------------------------------------------------------------------------
# Pinot Server:
# ------------------------------------------------------------------------------
server:
  name: server
  replicaCount: 5
  podManagementPolicy: Parallel
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}

  probes:
    endpoint: "/health"
    livenessEnabled: false
    readinessEnabled: false

  dataDir: /var/pinot/server/data/index
  segmentTarDir: /var/pinot/server/data/segment

  persistence:
    enabled: true
    accessMode: ReadWriteOnce
    size: 500Gi
    mountPath: /var/pinot/server/data
    storageClass: ""
    #storageClass: "ssd"

  jvmOpts: "-Xms32G -Xmx32G -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/oom_heap_dump.hprof -Xlog:gc*:file=/opt/pinot/gc-pinot-server.log -javaagent:/opt/pinot/etc/jmx_prometheus_javaagent/jmx_prometheus_javaagent-0.12.0.jar=8008:/opt/pinot/etc/jmx_prometheus_javaagent/configs/pinot.yml"

  log4j2ConfFile: /opt/pinot/conf/log4j2.xml
  pluginsDir: /opt/pinot/plugins

  service:
    annotations:
      "prometheus.io/scrape": "true"
      "prometheus.io/port": "8008"
    clusterIP: ""
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    type: ClusterIP
    nettyPort: 8098
    nettyPortName: netty
    adminPort: 8097
    adminExposePort: 80
    adminPortName: admin
    nodePort: ""
    protocol: TCP

  resources:
    requests:
      cpu: 7500m
      memory: 60Gi
    limits:
      cpu: 7500m
      memory: 60Gi

  nodeSelector: {}
#    aws.amazon.com/eks-local-ssd: "true"

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: alpha.eksctl.io/nodegroup-name
                operator: In
                values:
                  - "ng-pinot-server"

  tolerations: []

  podAnnotations:
    "prometheus.io/scrape": "true"
    "prometheus.io/port": "8008"

  updateStrategy:
    type: RollingUpdate

  # Use envFrom to define all of the ConfigMap or Secret data as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables
  envFrom: []
  #  - configMapRef:
  #      name: special-config
  #  - secretRef:
  #      name: test-secret

  # Use extraEnv to add individual key value pairs as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
  extraEnv: []
  #  - name: PINOT_CUSTOM_ENV
  #    value: custom-value

  # Extra configs will be appended to pinot-server.conf file
  extra:
    configs: |-
      pinot.set.instance.id.to.hostname=true
      pinot.server.instance.realtime.alloc.offheap=true
      pinot.server.instance.currentDataTableVersion=2
      pinot.server.storage.factory.class.s3=org.apache.pinot.plugin.filesystem.S3PinotFS
      pinot.server.storage.factory.s3.region=us-east-1
      pinot.server.segment.fetcher.protocols=file,http,s3
      pinot.server.segment.fetcher.s3.class=org.apache.pinot.common.utils.fetcher.PinotFSSegmentFetcher
#      pinot.server.instance.enableThreadCpuTimeMeasurement=true
#      pinot.query.scheduler.query_runner_threads=30
#      pinot.query.scheduler.query_worker_threads=60

# ------------------------------------------------------------------------------
# Pinot Minion:
# ------------------------------------------------------------------------------
minion:
  name: minion
  replicaCount: 1
  podManagementPolicy: Parallel
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}

  probes:
    endpoint: "/health"
    livenessEnabled: false
    readinessEnabled: false

  dataDir: /var/pinot/minion/data
  jvmOpts: "-Xms2G -Xmx4G -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xlog:gc*:file=/opt/pinot/gc-pinot-minion.log"

  log4j2ConfFile: /opt/pinot/conf/log4j2.xml
  pluginsDir: /opt/pinot/plugins

  persistence:
    enabled: true
    accessMode: ReadWriteOnce
    size: 30G
    mountPath: /var/pinot/minion/data
    storageClass: ""
    #storageClass: "ssd"

  service:
    annotations: {}
    clusterIP: ""
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []
    type: ClusterIP
    port: 9514
    nodePort: ""
    protocol: TCP
    name: minion

  resources:
    requests:
      cpu: 1700m
      memory: 8Gi
    limits:
      cpu: 1700m
      memory: 8Gi

  nodeSelector: {}

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pinot-minion-node
                operator: In
                values:
                  - "true"

  tolerations: []

  podAnnotations: {}

  updateStrategy:
    type: RollingUpdate

  # Use envFrom to define all of the ConfigMap or Secret data as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables
  envFrom: []
  #  - configMapRef:
  #      name: special-config
  #  - secretRef:
  #      name: test-secret

  # Use extraEnv to add individual key value pairs as container environment variables.
  # ref: https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
  extraEnv: []
  #  - name: PINOT_CUSTOM_ENV
  #    value: custom-value

  # Extra configs will be appended to pinot-minion.conf file
  extra:
    configs: |-
      pinot.set.instance.id.to.hostname=true
      pinot.minion.storage.factory.class.s3=org.apache.pinot.plugin.filesystem.S3PinotFS
      pinot.minion.storage.factory.s3.region=us-east-1
      pinot.minion.segment.fetcher.protocols=file,http,s3
      pinot.minion.segment.fetcher.s3.class=org.apache.pinot.common.utils.fetcher.PinotFSSegmentFetcher

# ------------------------------------------------------------------------------
# Zookeeper:
# NOTE: IN PRODUCTION USE CASES, IT's BEST TO USE ZOOKEEPER K8S OPERATOR
# ref: https://github.com/pravega/zookeeper-operator#install-the-operator
# ------------------------------------------------------------------------------

zookeeper:
  ## If true, install the Zookeeper chart alongside Pinot
  ## ref: https://github.com/kubernetes/charts/tree/master/incubator/zookeeper
  enabled: true

  ## If the Zookeeper Chart is disabled a URL override is required to connect
  urlOverride: "my-zookeeper:2181/my-pinot"

  ## Zookeeper port
  port: 2181

  ## Configure Zookeeper resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources:
    requests:
      cpu: 2000m
      memory: 4Gi
    limits:
      cpu: 2000m
      memory: 4Gi

  ## Replicas
  replicaCount: 1

  ## Environmental variables to set in Zookeeper
  env:
    ## The JVM heap size to allocate to Zookeeper
    ZK_HEAP_SIZE: "1024M"

  persistence:
    enabled: true
    ## The amount of PV storage allocated to each Zookeeper pod in the statefulset
    size: "15Gi"

  ## Specify a Zookeeper imagePullPolicy
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  image:
    PullPolicy: "IfNotPresent"

#  livenessProbe:
#    enabled: false
#  readinessProbe:
#    enabled: false
#  dataLogDir: /bitnami/zookeeper/datalog

  ## Ongoing data directory cleanup configuration
  autopurge:

    ## The time interval (in hours) for which the purge task has to be triggered
    ## Set to a positive integer to enable the auto purging
    purgeInterval: 24

    ## The most recent snapshots amount (and corresponding transaction logs) to retain
    snapRetainCount: 10

  #  podAnnotations:
#    prometheus.io/scrape: "true"
#    prometheus.io/path: "/metrics"
#    prometheus.io/port: "9141"
#
#  exporters:
#    zookeeper:
#      enabled: true
#    jmx:
#      enabled: true

  ## Pod scheduling preferences (by default keep pods within a release on separate nodes).
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## By default we don't set affinity:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: pinot-zookeper-node
                operator: In
                values:
                  - "true"
  # podAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     - topologyKey: "kubernetes.io/hostname"
  #       labelSelector:
  #         matchLabels:
  #           release: zookeeper
